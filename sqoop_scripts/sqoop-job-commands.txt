Azure:
sqoop-list-databases --connect "jdbc:mysql://sandbox-hdp.hortonworks.com:3306" --username root --password hadoop
beeline -u jdbc:hive2://sandbox-hdp.hortonworks.com:10000 -n maria_dev

ssh to root from azureuser:
ssh root@localhost -p 2222

scp to root from azureuser:
scp -P 2222 file.txt root@localhost:~/data

sqoop-job \
--create loadproducts \
-- import  \
--connect "jdbc:mysql://sandbox-hdp.hortonworks.com:3306/adventureworks" \
--username root \
--password hadoop \
--table v_product  \
--as-parquetfile \
--target-dir /user/cloudera/bigretail/output/stores/sqoop/products  \
--split-by productId \
--num-mappers 1 \
--check-column modifieddate \
--incremental lastmodified \
--driver com.mysql.jdbc.Driver



My versions:
#Salesorderdetail
sqoop-job \
--create loadsalesorderdetail \
-- import  \
--connect jdbc:mysql://quickstart:3306/adventureworks \
--username root \
--password cloudera \
--table v_salesorderdetails \
--as-parquetfile \
--target-dir /user/cloudera/bigretail/output/stores/sqoop/salesorderdetails  \
--split-by SalesOrderDetailID \
--num-mappers 1 \
--check-column SalesOrderDetailID \
--incremental append


#load credit card
sqoop job \
--create loadcreditcard \
-- import \
--connect jdbc:mysql://quickstart:3306/adventureworks \
--username root \
--table creditcard \
--as-parquetfile \
--target-dir /user/cloudera/bigretail/output/stores/sqoop/creditcard  \
--num-mappers 1 \
--check-column ModifiedDate \
--append \
--incremental lastmodified

#load products
sqoop-job \
--create loadproducts \
-- import  \
--connect jdbc:mysql://quickstart:3306/adventureworks \
--username root \
--password cloudera \
--table v_product  \
--as-parquetfile \
--target-dir /user/cloudera/bigretail/output/stores/sqoop/products  \
--split-by productId \
--num-mappers 1 \
--check-column modifieddate \
--incremental lastmodified

#load salesorderheader
sqoop-job \
--create loadsalesorderheader \
-- import  \
--connect jdbc:mysql://quickstart:3306/adventureworks \
--username root \
--password cloudera \
--table v_salesorderheader \
--as-parquetfile \
--target-dir /user/cloudera/bigretail/output/stores/sqoop/salesorderheader \
--split-by SalesOrderID \
--num-mappers 1 \
--check-column SalesOrderID \
--incremental append

#load customers
sqoop job \
--create loadcustomers \
-- import  \
--connect jdbc:mysql://quickstart:3306/adventureworks \
--username root \
--password cloudera \
--table v_customer  \
--as-parquetfile \
--target-dir /user/cloudera/bigretail/output/stores/sqoop/customers  \
--append \
--split-by CustomerID \
--num-mappers 1 \
--check-column ModifiedDate \
--incremental lastmodified


sqoop job --list
sqoop exec --loadcustomers











# sqoop script to create a new job to load customer data from rdbms to hdfs
sqoop-job --create loadcustomers -- import  --connect jdbc:mysql://quickstart:3306/adventureworks --username root \
--table v_customer  --as-parquetfile --target-dir /user/cloudera/bigretail/output/stores/sqoop/customers  --append \
--split-by CustomerID --num-mappers 1 --check-column ModifiedDate --incremental lastmodified \
--password-file /user/cloudera/passwordfile


# sqoop script to create a new job to load salesorderheader data from rdbms to hdfs
sqoop-job --create loadsalesorderheader -- import  --connect jdbc:mysql://quickstart:3306/adventureworks --username root \
--table v_salesorderheader --as-parquetfile \
--target-dir /user/cloudera/bigretail/output/stores/sqoop/salesorderheader  \
--split-by SalesOrderID --num-mappers 1 --check-column SalesOrderID --incremental append \
--password-file /user/cloudera/passwordfile


# sqoop script to create a new job to load salesorderdetails data from rdbms to hdfs
sqoop-job --create loadsalesorderdetail -- import  --connect jdbc:mysql://quickstart:3306/adventureworks --username root \
--table v_salesorderdetails  --as-parquetfile \
--target-dir /user/cloudera/bigretail/output/stores/sqoop/salesorderdetails  \
--split-by SalesOrderDetailID --num-mappers 1 --check-column SalesOrderDetailID --incremental append \
--password-file /user/cloudera/passwordfile


# sqoop script to create a new job to load v_product data from rdbms to hdfs
sqoop-job --create loadproducts -- import  --connect jdbc:mysql://quickstart:3306/adventureworks --username root \
--table v_product  --as-parquetfile \
--target-dir /user/cloudera/bigretail/output/stores/sqoop/products  \
--split-by productId --num-mappers 1 --check-column modifieddate --incremental lastmodified \
--password-file /user/cloudera/passwordfile

# sqoop job to load creditcard table
sqoop job --create loadcreditcard -- import --connect jdbc:mysql://quickstart:3306/adventureworks --username root \
--table creditcard --as-parquetfile --target-dir /user/cloudera/bigretail/output/stores/sqoop/creditcard  \ 
--num-mappers 1 --check-column ModifiedDate --append --incremental lastmodified --password-file /user/cloudera/passwordfile 





#to execute any of the jobs 
sqoop-job --exec loadsalesorderheader

